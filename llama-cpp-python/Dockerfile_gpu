# Use the image as specified
FROM nvidia/cuda:12.2.2-devel-ubuntu22.04 

# Update and upgrade the existing packages 
RUN apt-get update && apt-get upgrade -y && apt-get install -y --no-install-recommends \
    python3 \
    python3-pip \
    ninja-build \
    libopenblas-dev \
    build-essential \
    pkg-config

ARG llama_cpp_version

RUN CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python[server]==$llama_cpp_version

# We set some default values, but those could be overwritten
ENV HOST="localhost" \
    PORT="8000" \        
    CHATFORMAT="chatml" \
    N_CTX="2048"

WORKDIR /app

COPY start_server_gpu.sh /app/entrypoint.sh

ENTRYPOINT ["/app/entrypoint.sh"]
