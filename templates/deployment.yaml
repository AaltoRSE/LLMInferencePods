apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-{{ .Values.modelName }}
  namespace: rse
  labels:
    app.kubernetes.io/name: llm-{{ .Values.modelName }}
    app.kubernetes.io/component: server
# The definition of the service itself
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: llm-{{ .Values.modelName }}
      app.kubernetes.io/component: server
  template:
    metadata:
      labels:
        app.kubernetes.io/name: llm-{{ .Values.modelName }}
        app.kubernetes.io/component: server
    spec:
      nodeSelector:
        kubernetes.io/hostname: k8s-node21.cs.aalto.fi
      restartPolicy: Always
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      volumes:
        - name: llm-models
          hostPath:
            path: /srv/models/
            type: Directory

      containers:
        - name: llm-{{ .Values.modelName }}-cont
          image: harbor.cs.aalto.fi/aaltorse-public/llm_llama2:latest
          ports:
            - containerPort: 8000
          env:
            - name: MODEL
              value: /models/{{ .Values.modelPath }}
            - name: HOST
              value: "0.0.0.0"
            - name: PORT
              value: "8000"
          volumeMounts:
            - mountPath: /models
              name: llm-models
              readOnly: true
        - name: llm-nginx-cont
          image: harbor.cs.aalto.fi/aaltorse-public/llm_nginx:latest
          ports:
            - containerPort: 80
          env:
            - name: LLM_MODEL
              value: "model"
            - {
                name: AUTH_TOKEN,
                valueFrom:
                  { secretKeyRef: { name: llm-gateway, key: inference_key } },
              }

          securityContext:
            runAsUser: 0
            runAsGroup: 0
            allowPrivilegeEscalation: false
